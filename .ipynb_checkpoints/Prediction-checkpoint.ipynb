{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "### High level overview\n",
    "Imagine at T-shaped intersection.You are a self-driving car that has just pulled up to the stop sign.You want to turn left but your sensors notice another vehicle coming from the left.Now, let's pause for a moment.At this point, you as a human probably know the green vehicle will do one of two things,either it will go straight or it will go right.\n",
    "Well, let's say that at this point,the green vehicle starts slowing down and moving right in the lane.Well, you probably know that they are turning right which means it is safe for you to go left.By making a successful prediction,you were able to make a decision that got you to your destination safely and efficiently.And what makes prediction interesting but alsochallenging is that it is inherently multi-modal.A good way of thinking about what thatmeans is to think of how you would answer the question,\"Where is the green car likely to be in five seconds?\"If we try to come up with the probability distribution,we would see that it has multiple peaks or moats.If the car is going straight,then the car is likely to be somewhere here.But if the car turns right,then it's more likely to be here.And in general, the way we think about handling multi-modal uncertainty is\n",
    "by maintaining some beliefs about how probable each potential mode is.Initially, if we just see this green car coming from far away,those beliefs could be initialized using some prior knowledge about this intersection.In this case, let's say that cars generally go straight at this intersection.But as we continue watching the car,we may notice that it is slowing down.Since this behavior is more consistent with turning right,the probability of turning right increases.And then, at the next timestep,we might notice that the car has already started turning right which again increases the probability of turning right.And as we keep observing,we continue updating our belief based on new evidence until eventually we can predict with high certainty that the vehicle is turning right at this intersection.So the responsibility of the prediction module is to do the following: We take as input a map of the world and data from sensor fusion and generate as output some predictions of the future state of all the vehicles and other moving objects in the vicinity of our vehicle.Typically, these predictions are represented by a set of possible trajectories like that two dotted arrows emanating from the green car in this scenario and an associated probability for each trajectory.Before we get into the details,let me explain what we are going to discuss in this lesson.First, we'll go through a brief overview where you will learn a bit more about the inputs and outputs to prediction.Next, we will talk about how prediction is actually done.We will discuss the two main classes of prediction techniques,model-based approaches and data-driven approaches.There, model-based approaches use mathematical models of motion to predict trajectories and data-driven approaches rely on machine learning and examples to learn from.Then, I will briefly walk you through how to apply strictly data-driven approach for prediction called trajectory clustering.Then, we will dig into model-based approaches where I'll introduce process models as a mathematical technique for modeling various maneuvers like lane changes, vehicle following, etc.And introduce multi-modal estimators as an effective technique for handling the uncertainty associated with prediction,namely, the uncertainty about which maneuver an object will do in a particular situation.Finally, we will dive deep into hybrid approaches which use data and process models to predict motion through a cycle of intense classification where we try to figure out what a driver wants to do and trajectory generation.There we try to figure out how they are likely to do it.We will end by implementing an algorithm called Naive Bayes to predict the motion of a car at a T-shaped intersection like the one you just saw.In the next few segments,\n",
    "I'm going to ask you to do some reading about the data processing that happens in a typical prediction module.\n",
    " \n",
    "<img src=\"./outputs/prediction1.png\" width=\"600\" height=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"././outputs/prediction2.png\" width=\"600\" height=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"././outputs/prediction3.png\" width=\"600\" height=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs and Outputs to Prediction\n",
    "<img src=\"././outputs/prediction_io.jpg\" width=\"600\" height=\"600\" />\n",
    "\n",
    "A prediction module uses a **map** and **data** from **sensor fusion** to generate predictions for what all other **dynamic objects** in view are likely to do. To make this clearer, let's look at an example (in json format) of what the **input** to and **output** from prediction might look like.\n",
    "\n",
    "Example Input - Sensor Fusion:\n",
    "\n",
    "    {\n",
    "        \"timestamp\" : 34512.21,\n",
    "        \"vehicles\" : [\n",
    "            {\n",
    "                \"id\"  : 0,\n",
    "                \"x\"   : -10.0,\n",
    "                \"y\"   : 8.1,\n",
    "                \"v_x\" : 8.0,\n",
    "                \"v_y\" : 0.0,\n",
    "                \"sigma_x\" : 0.031,\n",
    "                \"sigma_y\" : 0.040,\n",
    "                \"sigma_v_x\" : 0.12,\n",
    "                \"sigma_v_y\" : 0.03,\n",
    "            },\n",
    "            {\n",
    "                \"id\"  : 1,\n",
    "                \"x\"   : 10.0,\n",
    "                \"y\"   : 12.1,\n",
    "                \"v_x\" : -8.0,\n",
    "                \"v_y\" : 0.0,\n",
    "                \"sigma_x\" : 0.031,\n",
    "                \"sigma_y\" : 0.040,\n",
    "                \"sigma_v_x\" : 0.12,\n",
    "                \"sigma_v_y\" : 0.03,\n",
    "            },\n",
    "        ]\n",
    "    }\n",
    "\n",
    "Example Output\n",
    "\n",
    "    {\n",
    "        \"timestamp\" : 34512.21,\n",
    "        \"vehicles\" : [\n",
    "            {\n",
    "                \"id\" : 0,\n",
    "                \"length\": 3.4,\n",
    "                \"width\" : 1.5,\n",
    "                \"predictions\" : [\n",
    "                    {\n",
    "                        \"probability\" : 0.781,\n",
    "                        \"trajectory\"  : [\n",
    "                            {\n",
    "                                \"x\": -10.0,\n",
    "                                \"y\": 8.1,\n",
    "                                \"yaw\": 0.0,\n",
    "                                \"timestamp\": 34512.71\n",
    "                            },\n",
    "                            {\n",
    "                                \"x\": -6.0,\n",
    "                                \"y\": 8.1,\n",
    "                                \"yaw\": 0.0,\n",
    "                                \"timestamp\": 34513.21\n",
    "                            },\n",
    "                            {\n",
    "                                \"x\": -2.0,\n",
    "                                \"y\": 8.1,\n",
    "                                \"yaw\": 0.0,\n",
    "                                \"timestamp\": 34513.71\n",
    "                            },\n",
    "                            {\n",
    "                                \"x\": 2.0,\n",
    "                                \"y\": 8.1,\n",
    "                                \"yaw\": 0.0,\n",
    "                                \"timestamp\": 34514.21\n",
    "                            },\n",
    "                            {\n",
    "                                \"x\": 6.0,\n",
    "                                \"y\": 8.1,\n",
    "                                \"yaw\": 0.0,\n",
    "                                \"timestamp\": 34514.71\n",
    "                            },\n",
    "                            {\n",
    "                                \"x\": 10.0,\n",
    "                                \"y\": 8.1,\n",
    "                                \"yaw\": 0.0,\n",
    "                                \"timestamp\": 34515.21\n",
    "                            },\n",
    "                        ]\n",
    "                    },\n",
    "                    {\n",
    "                        \"probability\" : 0.219,\n",
    "                        \"trajectory\"  : [\n",
    "                            {\n",
    "                                \"x\": -10.0,\n",
    "                                \"y\": 8.1,\n",
    "                                \"yaw\": 0.0,\n",
    "                                \"timestamp\": 34512.71\n",
    "                            },\n",
    "                            {\n",
    "                                \"x\": -7.0,\n",
    "                                \"y\": 7.5,\n",
    "                                \"yaw\": -5.2,\n",
    "                                \"timestamp\": 34513.21\n",
    "                            },\n",
    "                            {\n",
    "                                \"x\": -4.0,\n",
    "                                \"y\": 6.1,\n",
    "                                \"yaw\": -32.0,\n",
    "                                \"timestamp\": 34513.71\n",
    "                            },\n",
    "                            {\n",
    "                                \"x\": -3.0,\n",
    "                                \"y\": 4.1,\n",
    "                                \"yaw\": -73.2,\n",
    "                                \"timestamp\": 34514.21\n",
    "                            },\n",
    "                            {\n",
    "                                \"x\": -2.0,\n",
    "                                \"y\": 1.2,\n",
    "                                \"yaw\": -90.0,\n",
    "                                \"timestamp\": 34514.71\n",
    "                            },\n",
    "                            {\n",
    "                                \"x\": -2.0,\n",
    "                                \"y\":-2.8,\n",
    "                                \"yaw\": -90.0,\n",
    "                                \"timestamp\": 34515.21\n",
    "                            },\n",
    "                        ]\n",
    "\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"id\" : 1,\n",
    "                \"length\": 3.4,\n",
    "                \"width\" : 1.5,\n",
    "                \"predictions\" : [\n",
    "                    {\n",
    "                        \"probability\" : 1.0,\n",
    "                        \"trajectory\" : [\n",
    "                            {\n",
    "                                \"x\": 10.0,\n",
    "                                \"y\": 12.1,\n",
    "                                \"yaw\": -180.0,\n",
    "                                \"timestamp\": 34512.71\n",
    "                            },\n",
    "                            {\n",
    "                                \"x\": 6.0,\n",
    "                                \"y\": 12.1,\n",
    "                                \"yaw\": -180.0,\n",
    "                                \"timestamp\": 34513.21\n",
    "                            },\n",
    "                            {\n",
    "                                \"x\": 2.0,\n",
    "                                \"y\": 12.1,\n",
    "                                \"yaw\": -180.0,\n",
    "                                \"timestamp\": 34513.71\n",
    "                            },\n",
    "                            {\n",
    "                                \"x\": -2.0,\n",
    "                                \"y\": 12.1,\n",
    "                                \"yaw\": -180.0,\n",
    "                                \"timestamp\": 34514.21\n",
    "                            },\n",
    "                            {\n",
    "                                \"x\": -6.0,\n",
    "                                \"y\": 12.1,\n",
    "                                \"yaw\": -180.0,\n",
    "                                \"timestamp\": 34514.71\n",
    "                            },\n",
    "                            {\n",
    "                                \"x\": -10.0,\n",
    "                                \"y\": 12.1,\n",
    "                                \"yaw\": -180.0,\n",
    "                                \"timestamp\": 34515.21\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "Notes:\n",
    "\n",
    "1. The predicted trajectories shown here only extend out a few seconds. In reality the predictions we make extend to a horizon of 10-20 seconds.\n",
    "2. The trajectories shown have 0.5 second resolution. In reality we would generate slightly finer-grained predictions.\n",
    "3. This example only shows vehicles but in reality we would also generate predictions for all dynamic objects in view."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-Based vs Data-Driven Approaches\n",
    "Imagine a T-shaped intersection.The blue self-driving car pulls up to that stop sign and wouldlike to make a left turn but it sees this green car coming from the left.If the green car is turning right,it is safe for the blue car to go.But if the green car is going straight,then the blue car should wait.The way we would handle this with the model based approach is as follows:\n",
    "\n",
    "1. First we would come up with two process models,one for going straight and one for turning right.And we would use some simple trajectory generator to figure outwhat trajectory we would expect to see ifthe driver were going straight or turning right.\n",
    "2. Then we would pay attention to the actual behavior of the target vehicle and using a multimodal estimation algorithm which is still a black box for now we would compare observed trajectory to the ones we would expect for each of our models.\n",
    "3. And then based on that we would assign a probability to each of the possible trajectories.But the important takeaway for purely model based prediction is that we have some bank of possible behaviors and each has a mathematical model of motion which takes into account the physical capabilities of the object as well as the constraints imposed by the road traffic laws and other restrictions.\n",
    "\n",
    "What about a data driven approach. Well with the purely data driven approach we have a truly blackbox algorithm and this algorithm will be trained on lots of training data.Once it's trained we just fitted the observed behavior and let it make a prediction about what will happen next.So we can see that each approach has its own strengths.Model based approaches incorporate our knowledge of physics constraints imposed by the road traffic et cetera and data driven approaches are nice because they let us use data to extract subtle patterns that would otherwise be missed by model based approaches.For example differences in vehicle behavior at an intersection during different times of the day.And this leads to the somewhat leading question.Which approach is the best.\n",
    "\n",
    "<img src=\"././outputs/prediction4.png\" width=\"600\" height=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which approach is best?\n",
    "\n",
    "Which is best?\n",
    "Neither approach (**model based** or **data driven**) is strictly better than the other but there are certain situations in which one is more useful than the other. Think about the following situations and whether model-based or data-driven approaches would be more useful:\n",
    "\n",
    "1. Determining maximum safe turning speed on a wet road. --> **Model Based**\n",
    "\n",
    "    * In this situation we could use a model based approach to incorporate our knowledge of physics (friction, forces, etc...) to figure out exactly (or almost exactly) when a vehicle would begin to skid on a wet road.\n",
    "\n",
    "2. Predicting the behavior of an unidentified object sitting on the road. --> **Data Driven**\n",
    "\n",
    "    * Even with data driven approaches this would still be a very hard problem but since we don't even know what this object is, a model based approach to prediction would be nearly impossible.\n",
    "    \n",
    "3. Predicting the behavior of a vehicle on a two lane highway in light traffic. --> **Data Driven**\n",
    "\n",
    "    * Either approach (or a hybrid approach) can be used in this situation.On the one hand there are very few behaviors we need to model in a highway driving situation and the physics are all very well understood so model based approaches could work.On the other hand it would be relatively easy to collect a lot of training data in similar situations so a purely data driven approach could work too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Driven Example - Trajectory Clustering\n",
    "\n",
    "**Trajectory is x,y,heading w.r.t. time predicted over 10-20 seconds time**\n",
    "\n",
    "There are many ways that machine learning algorithms can be used in purely data driven approaches for prediction. Since you already went through a machine learning class, we won't go into these techniques into much detail. But in this video, I would like to show you one example that is representative of what these algorithms are good at-- **Trajectory clustering**. As is the case with all data driven prediction techniques, there will be two phases:\n",
    "\n",
    "1. An offline training phase where the algorithm learns a model from data.\n",
    "\n",
    "2. online prediction phase where it uses that model to generate predictions. \n",
    "\n",
    "Let's discuss the offline face first. The first step is to get a lot of data which you might do by placing a static camera at an intersection. Then, we have to clean the data since some of the cars we observe may be occluded or something else went wrong in the processing step. So we need to discard the bad data. Once the data is gathered and cleaned up, we would be left with a bunch of trajectories that look something like this. \n",
    "\n",
    "<img src=\"./outputs/traj_clustering1.png\" width=\"600\" height=\"600\" />\n",
    "\n",
    "Next, we need to define some **mathematical measure of trajectory similarity** and there are many ways to do this but intuitively we want something that says a trajectory like this one in red is more similar to this one in pink than it is to this one in blue, even though they're red and blue trajectories overlap more closely for a while than the red and pink ever do. \n",
    "<img src=\"./outputs/traj_clustering2.png\" width=\"600\" height=\"600\" />\n",
    "\n",
    "If you're interested in learning more, I will include a link to a [paper](./outputs/trajectory-clustering.pdf) that discuss measures of similarity in detail.\n",
    "\n",
    "Once we have a measure of similarity we can use a machine learning algorithm like **[agglomerative clustering](https://en.wikipedia.org/wiki/Cluster_analysis#agglomerative_clustering)** or a **[spectral clustering](https://en.wikipedia.org/wiki/Spectral_clustering)** to clustered these trajectories. \n",
    "\n",
    "In the case of a four-way stop intersection, we would expect to see 12 clusters since at each of the four stop signs cars can do one of three things: \n",
    "1. turn right, \n",
    "2. go straight or \n",
    "3. turn left.\n",
    "\n",
    "**NOTE:** 4 for each case because (and 3 directions make it 12 total), in the 4 way it depends on arrival time of the vehicle, if arrived first move first after stop, if second wait till one the vehicle has gone and then move, if third wait till 2 of the vehicles are gone and last if fourth wait till all the vehicles arrived before this vehicle are gone. So, sequence generator which observed which vehicles arrived before as well will be needed. Actually not, as trajectory output has time filed in it, but what is needed is knowledge of how many vehicles are waiting at stop sign before this vehicles arrival (object recognition).\n",
    "\n",
    "So if we were looking at just one of those four stop signs, we would expect to see a cluster of trajectories for left turns, going straight, and turning right. \n",
    "<img src=\"./outputs/traj_clustering3.png\" width=\"600\" height=\"600\" />\n",
    "\n",
    "\n",
    "\n",
    "Note that in some situations you may obtain even more clusters than that. For example, if this lane is controlled by a traffic light instead of stop, your clustering algorithm will probably create twice as many clusters. Three of them go through the intersection without stopping and three of them stop at the traffic light first. \n",
    "\n",
    "**NOTE:** the trajectory will depend on light status (green/red/orange), and delay (no delay for green/orange) in trajectories should take care of duration of light which is similar to 4-way stop situation + no stop. (How about protected left turns, can be treated as 4-way, only additional variance is that the wait has to be done at middle of lane and make sure oncoming traffic is cleared before truning)\n",
    "\n",
    "<img src=\"./outputs/traj_clustering4.png\" width=\"600\" height=\"600\" />\n",
    "\n",
    "\n",
    "Once the trajectories have been grouped into clusters, it is useful to define what prototype trajectories look like for each cluster. For the left turn cluster, maybe these three trajectories are a good model. They provide a compact representation of what left turns typically look like at this intersection. At this point, we have a trained model of typical car behavior at this intersection. The next step is to use this model on the road to actually generate predictions. \n",
    "<img src=\"./outputs/traj_clustering5.png\" width=\"600\" height=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory Clustering 2 - Online Prediction\n",
    "\n",
    "Once our clustering algorithm has identified clusters and prototype trajectories, in this case three clusters with three prototype trajectories each, we can begin the job of online prediction for a vehicle that we meet on the road. \n",
    "1. First, we observed the vehicle's partial trajectory.\n",
    "2. Next we compare it to the corresponding segments of the prototype trajectories for each cluster. \n",
    "    * This comparison is done using the **same similarity measure we used earlier to perform the clustering**.\n",
    "3. The belief for each cluster is updated based on how similar the partial trajectory is to the prototype trajectories.\n",
    "4. And finally, we compute a predicted trajectory for each cluster.For example, by taking the most similar prototype trajectory. \n",
    "\n",
    "Let's make this more clear by following this car forward in time from T equals zero to T equals one. Let's go through these steps. One, we observe the partial trajectory between time zero and one. It is this green line behind the vehicle. \n",
    "\n",
    "<img src=\"./outputs/traj_clustering6.png\" width=\"600\" height=\"600\" />\n",
    "\n",
    "Two, well since all of the prototype trajectories overlap up to this point, the trajectory comparison step will yield the same probability for each cluster. \n",
    "\n",
    "<img src=\"./outputs/traj_clustering7.png\" width=\"600\" height=\"600\" />\n",
    "\n",
    "Three, even though there is no clear winner within each cluster we still have to choose one prototype trajectory to represent each cluster and we broadcast these three trajectories with their associated probabilities. \n",
    "<img src=\"./outputs/traj_clustering8.png\" width=\"600\" height=\"600\" />\n",
    "\n",
    "Next, a T equal two- things get more interesting. First, let's get rid of the car so we can see the trajectory more clearly. Now when you make a comparison of the partial trajectory with the nine prototype trajectories, we find that the vehicle's partial trajectory seems more similar to the red than purple or blue. When we update the associated probabilities we might get something like this. \n",
    "\n",
    "<img src=\"./outputs/traj_clustering9.png\" width=\"600\" height=\"600\" />\n",
    "\n",
    "Note that red grows in probability and the blue and purple both shrink, but blue shrinks more than purple since the partial trajectory is a worse match for blue. Then, we pick the best prototype trajectory for each cluster and use them to represent the future trajectory of the car. \n",
    "<img src=\"./outputs/traj_clustering10.png\" width=\"600\" height=\"600\" />\n",
    "\n",
    "As we continue this process, we see the probability for the red cluster quickly approaches one. \n",
    "<img src=\"./outputs/traj_clustering11.png\" width=\"600\" height=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thinking about Model Based Approaches\n",
    "\n",
    "Data driven approaches can be very useful particularly when we have access to plenty of training data. But in some ways purely data driven approaches are nÃve since they rely solely on historical evidence to make predictions about likely future behavior. Ideally, we would also like to include, in our predictions, all the insights we have about driver behavior, physics, or vehicle dynamics. This is where model based approaches can help. The way these approaches typically work is as follows:\n",
    "\n",
    "* For each **object** identify all the **behaviors** that object is likely to do in the current situation. The behavior for a vehicle could be something like **change lanes, turn left** and **for a pedestrian, it could be cross the street on pedestrian crossing**. For our intersection scenario, the behaviors could be go straight, turn left, turn right. Whatever it is, it needs to be something that we can describe mathematically. \n",
    "* Step two, define a process model for each behavior. A process model is a mathematical description of object motion for behavior. It is a function which can be used to compute the state of the object at time t+1 from the state at time t. The process model must incorporate some uncertainty which represents how much we trust our model. In our intersection example, the left turn process model would produce an uncertain future state located roughly here.\n",
    "<img src=\"./outputs/traj_clustering12.png\" width=\"400\" height=\"400\" />\n",
    "\n",
    "The going straight process model would produce an uncertain future state located roughly here\n",
    "<img src=\"./outputs/traj_clustering13.png\" width=\"400\" height=\"400\" />\n",
    "\n",
    "\n",
    "and the right turn process model would produce an uncertain future state located roughly here.\n",
    "<img src=\"./outputs/traj_clustering14.png\" width=\"400\" height=\"400\" />\n",
    "\n",
    "If you keep running the process models your uncertainty will increase.\n",
    "<img src=\"./outputs/traj_clustering15.png\" width=\"400\" height=\"400\" />\n",
    "\n",
    "* Once we have a process model for each behavior we can go to the next step, step three, which is to use the process models to compute the probability of each behavior. This is done by taking the observed state of the object at time t-1, running the process models to compute the expected state of the object at time t. Then we compare the observed state of the object at time t with what our process models predicted. And we use a multimodal estimation algorithm to derive the probability of each maneuver. The purpose of these algorithms is to maintain some belief about how likely it is that the driver intends to perform each behavior. We'll go into more detail later. But in this case the probability of going straight or turning left would be higher than the probability of turning right. \n",
    "<img src=\"./outputs/traj_clustering16.png\" width=\"400\" height=\"400\" />\n",
    "\n",
    "* The fourth and final step is to predict a trajectory for each behavior. This is done easily by iterating on the process models until the prediction horizon is reached.\n",
    "<img src=\"./outputs/traj_clustering17.png\" width=\"400\" height=\"400\" />\n",
    "\n",
    "In the following videos, we talk more about the process models we use to model behaviors and then discuss one version of multimodal estimation algorithm that can be used to maintain beliefs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frenet Coordinates\n",
    "\n",
    "Before we discuss process models, we should mention \"Frenet Coordinates\", which are a way of representing position on a road in a more intuitive way than traditional (x,y)(x,y) Cartesian Coordinates.\n",
    "\n",
    "With Frenet coordinates, we use the variables **s** and **d** to describe a vehicle's position on the road. The s coordinate represents distance along the road (also known as **longitudinal displacement**) and the d coordinate represents side-to-side position on the road (also known as **lateral displacement**).\n",
    "\n",
    "Why do we use Frenet coordinates? Imagine a curvy road like the one below with a Cartesian coordinate system laid on top of it...\n",
    "<img src=\"./outputs/frenet-1.png\" width=\"200\" height=\"200\" />\n",
    "\n",
    "Using these Cartesian coordinates, we can try to describe the path a vehicle would normally follow on the road...\n",
    "<img src=\"./outputs/frenet-2.png\" width=\"200\" height=\"200\" />\n",
    "\n",
    "<img src=\"./outputs/frenet-3.png\" width=\"200\" height=\"200\" />\n",
    "\n",
    "And notice how curvy that path is! If we wanted equations to describe this motion it wouldn't be easy!\n",
    "\n",
    "x(t) = ?\n",
    "\n",
    "y(t) = ?\n",
    "\n",
    "Ideally, it should be mathematically easy to describe such common driving behavior. But how do we do that? One way is to use a new coordinate system. Now instead of laying down a normal Cartesian grid, we do something like you see below...\n",
    "\n",
    "\n",
    "<img src=\"./outputs/frenet-4.png\" width=\"200\" height=\"200\" />\n",
    "\n",
    "Here, we've defined a new system of coordinates. At the bottom we have s=0 to represent the beginning of the segment of road we are thinking about and d=0 to represent the center line of that road. To the left of the center line we have negative d and to the right dd is positive.\n",
    "\n",
    "So what does a typical trajectory look like when presented in Frenet coordinates?\n",
    "\n",
    "<img src=\"./outputs/frenet-5.png\" width=\"200\" height=\"200\" />\n",
    "<img src=\"./outputs/frenet-6.png\" width=\"200\" height=\"200\" />\n",
    "\n",
    "It looks straight!\n",
    "\n",
    "In fact, if this vehicle were moving at a constant speed of v 0,we could write a mathematical description of the vehicle's position as:\n",
    "\n",
    "s(t)=v<sub>0</sub>(t)\n",
    "\n",
    "d(t)=0\n",
    "\n",
    "We'll be working with Frenet coordinates a good deal in the rest of the course, because...\n",
    "<img src=\"./outputs/frenet-7.png\" width=\"200\" height=\"200\" />\n",
    "\n",
    "...straight lines are so much easier than curved ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Models\n",
    "Let's consider a process model for a situation where self-driving car is trying to merge on a highway where there is already is a vehicle in the right-most lane.This vehicle might do few of the following things:\n",
    "1. ignore us\n",
    "2. might speed up to let us merge behind it\n",
    "3. slow down to let us merge ahead of it\n",
    "4. change lane towards left\n",
    "\n",
    "For each of these behaviors,we want to come up with process models that formalizes the likely motion of the vehicle:\n",
    "Here is the behavior pictorially with corresponding process model:\n",
    "<img src=\"./outputs/pmodel1.png\" width=\"600\" height=\"600\" />\n",
    "\n",
    "Term **Lane following** will come up a lot in SDC.What is lane following and how do we describe it mathematically?\n",
    "There are many options, in general there is a trade-off between simplicity and accuracy when choosing process model.\n",
    "One siple approach is to treat the car as a point particle with **Holonomic** properties (Remember Model predictice control chapter in Term2??).This means we assume the car can move in any direction at any time, which ofcourse is not true (very simplistic).The simplest motion model are linear. Constant velocity lane following in Frenet coordinates would look something like this:\n",
    "\n",
    "<img src=\"./outputs/pmodel2.png\" width=\"300\" height=\"300\" />\n",
    "Where the car moves forward at each time step and is assumed to keep a constant distance to lane center. In practice linear point models usually windup being too simplictic.\n",
    "\n",
    "The next step in complexity happens when we allow nonlinearities into our model.Typically if you start incorporating heading into our state vector you will end up with sines and cosines in our model equations.An example of a non-linear model of lane following could like this in cartesian cordinates.\n",
    "\n",
    "<img src=\"./outputs/pmodel3.png\" width=\"300\" height=\"300\" />\n",
    "Note the presense of cosine and sine which is where the non-linearity comes from.\n",
    "\n",
    "Next jump in complexity happens when we take into account that a car is a **nonholonomic** system. A popular approach is to use a **bicycle model** which looks like this in an inertial cartesian reference frame.\n",
    "<img src=\"./outputs/pmodel4.png\" width=\"300\" height=\"300\" />\n",
    "\n",
    "A Bicycle model takes 2 inputs, the steering angle and acceleration. For steering angle, we could use a PID controller with the target lane's center line as the reference line. \n",
    "<img src=\"./outputs/pmodel5.png\" width=\"300\" height=\"300\" />\n",
    "For acceleration, we could once again use a constant velocity model or a constant acceleration model or if we wanted more complex acceleration behavior we could use a PID controller with the speed limit as a target (**Note:** I didn't implement this in the PID-controller project,instead went with speed vs steering angle limit). In practice,these sorts of model tends to strike a good balance between simplicity and accuracy.\n",
    "You could alwas make the model more complaex adding details about vehice dynamics. EX:\n",
    "use a dynamic bicycle model which looks like this:\n",
    "<img src=\"./outputs/pmodel6.png\" width=\"300\" height=\"300\" />\n",
    "\n",
    "Note the presence of terms like F<sub>c,f</sub> which represents lateral force on the tires at front of the vehicle and F<sub>c,r</sub> represents lateral force of the rear tire. Even more complexity can be added to the model by adding model for 4 wheels of the car.\n",
    "\n",
    "While these models are technically more accurate than any of the others,in practice using them doesn't usually make sense for prediction.There is so much uncertainty into predicting the behaviors of other drivers that minor accuracy improvements to process models just aren't worth the computational overhead that they come with.\n",
    "\n",
    "Note, how all the models contain an aditional term **W**. This is where the uncertainty on the process model is stored.A classic choice to represent uncertainty is a multivariate Gaussian with zero mean.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More on Process Models\n",
    "Later in the lesson I'm going to ask you to read a paper titled [\"A comparative study of multiple-model algorithms for maneuvering target tracking\"](./a-comparative-study-of-multiple-model-algorithms-for-maneuvering-target-tracking.pdf) but for now I'd like you to take a look at section 3.1 and 3.2 only of the paper. This section, titled **MM Tracking Algorithms' Design**, discusses the 9 process models used in the earlier part of the paper.\n",
    "\n",
    "Before you read the section, I'll explain some of the uncommon notation you will see.\n",
    "\n",
    "Notes on Notation:\n",
    "1 Matrix Notation\n",
    "When you see something like the following:\n",
    "\n",
    "F<sub>CV</sub>= diag[F<sub>2</sub>,F<sub>2</sub>],F<sub>2</sub>=\n",
    "$ \\begin{pmatrix}\n",
    "1 & T \\\\\n",
    "0 & 1\n",
    "\\end{pmatrix} $\n",
    "\n",
    "G= diag[G<sub>2</sub>,G<sub>2</sub>],G<sub>2</sub>=\n",
    "$ \\begin{pmatrix}\n",
    "T^2/2 \\\\\n",
    "T\n",
    "\\end{pmatrix} $\n",
    "\n",
    "it means that **F** is a 4x4 matrix, with F<sub>2</sub> as blocks along the diagonal. Written out fully, this means:\n",
    "\n",
    "F<sub>CV</sub>=$ \\begin{pmatrix}\n",
    "1 & T & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & T \\\\\n",
    "0 & 0 & 0 & 1\n",
    "\\end{pmatrix} $\n",
    "\n",
    "G=$ \\begin{pmatrix}\n",
    "T^2/2 0 \\\\\n",
    "0 & T  \\\\\n",
    "\\end{pmatrix} $\n",
    "\n",
    "\n",
    "2 State Space\n",
    "The process models all use cartesian coordinates. The state space is:\n",
    "x= $\\begin{pmatrix}\n",
    "x \\\\\n",
    "x' \\\\\n",
    "y \\\\\n",
    "y'\n",
    "\\end{pmatrix} $\n",
    "\n",
    "3 Variables\n",
    "The equation \n",
    "<math>\n",
    "x<sub>k</sub>=Fx<sub>k-1</sub> + Gu<sub>k-1</sub> + Gw<sub>k</sub>,w<sub>k</sub> ~ eta<box>(0,Q)</box)\n",
    "</math>\n",
    "\n",
    "the predicted state at time k (x<sub>k</sub>) is given by evolving (**F**) the previous state (x<sub>k−1</sub>), incorporating (**G**) the controls (u<sub>k−1</sub>) given at the previous time step, and adding **normally distributed noise** (w<sub>k</sub>).\n",
    "\n",
    "u<sub>k-1</sub>=0\n",
    "\n",
    "T=1s\n",
    "\n",
    "## from Paper's section 3\n",
    "---\n",
    "### Section 3.1\n",
    "\n",
    "Each MM tracking algorithm uses nine target motion models. The model set consists of **one non-maneuver** model, which is the (nearly) constant velocity (CV) model, and **eight maneuver models**. Four of the maneuver models model a **constant tangential acceleration (CTA)**, i.e., in the velocity direction. The CTA filters do not estimate the acceleration but rather they use a preset acceleration that acts as a constant input. The CTA models used by the filters are CTA (67 m/s<sup>2</sup>),CTA(−67 m/s<sup>2</sup>,CTA (33 m/s<sup>2</sup>, CTA(−33 m/s<sup>2</sup>, which model constant accelerations at approximately ±7g and ±3.5g.\n",
    "\n",
    "Another set of accelerations modeled are those in the **direction normal to the velocity**, which model **constant turns (CT)**. They are CT(14 deg/s), CT(−14 deg/s), CT(7 deg/s), CT(−7 deg/s).\n",
    "\n",
    "These nine models cover eight different target maneuver cases and the case with no maneuver.\n",
    "All models are in the generic state-space :\n",
    "<math>\n",
    "x<sub>k</sub>=Fx<sub>k-1</sub> + Gu<sub>k-1</sub> + Gw<sub>k</sub>,w<sub>k</sub> ~ Nu<box>(0,Q)</box)\n",
    "</math>\n",
    "\n",
    "**CV:**\n",
    "\n",
    "F<sub>CV</sub>= diag[F<sub>2</sub>,F<sub>2</sub>],F<sub>2</sub>=\n",
    "$ \\begin{bmatrix}\n",
    "1 & T \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix} $\n",
    "\n",
    "G= diag[G<sub>2</sub>,G<sub>2</sub>],G<sub>2</sub>=\n",
    "$ \\begin{bmatrix}\n",
    "T^2/2 \\\\\n",
    "T\n",
    "\\end{bmatrix} $\n",
    "\n",
    "u<sub>k-1</sub>=0\n",
    "\n",
    "T=1s\n",
    "\n",
    "**CTA:**\n",
    "\n",
    "F<sub>CTA</sub>=F<sub>CV</sub>;u<sub>k-1</sub>=u<sup>^</sup><sub>k-1</sub>=\n",
    "\n",
    "$ \\frac{a_{t}}{\\sqrt(x'_{k-1}+y'_{k-1})} \\begin{bmatrix} \n",
    "x'_{k-1} \\\\\n",
    "y'_{k-1}\n",
    "\\end{bmatrix}\n",
    "$  a<sub>t</sub> is given\n",
    "\n",
    "Each of the CTA models assumes a preset, tangential acceleration at (≈ ±67, ± 33 m/s<sup>2</sup> respectively) and the conditional Kalman filters do not estimate acceleration.The direction of the velocity (the unit vector above) is evaluated at each iteration k using the velocity (x<sup>.^</sup><sub>k−1</sub>, y<sup>.^</sup><sub>k−1</sub>) estimated at time k.\n",
    "\n",
    "\n",
    "**CT:**\n",
    "F<sub>CT</sub>= $ \\begin{bmatrix}\n",
    "1 & \\frac {sin\\omega T}{\\omega} & 0 & \\frac{1- cos\\omega T}{\\omega} \\\\\n",
    "0 & cos\\omega T & 0 & -sin\\omega T \\\\\n",
    "0 & \\frac {1 - cos\\omega T}{\\omega} & 1 & \\frac{sin\\omega T}{\\omega} \\\\\n",
    "0 & sin\\omega T & 0 & cos\\omega T\n",
    "\\end{bmatrix} \n",
    "$ , u<sub>k-1</sub>=0\n",
    "\n",
    "The CT models assume a nearly constant turn to the right or left. The values for the turn rate, ω (≈ ±14, ± 7 deg /s respectively), were determined approximately to cover 7g, and 3.5g maneuvers at an expected speed of 330m/s.\n",
    "\n",
    "### Section 3.2 Process Noises\n",
    "Since the Kalman filter was used for conditional filtering, the covariance $Q =diag \\begin{bmatrix}\n",
    "\\sigma ^2_{w}, \\sigma ^2_{w}\n",
    "\\end{bmatrix} \n",
    "$ of the process noise w = [w<sub>x</sub>, w<sub>y</sub>]′ are also needed. Each MM tracking algorithm used the same σ<sub>w</sub> = 2.25m/s2 for the CV model and σw = 50m/s2 for all maneuver models. These values were experimentally tuned to provide acceptable tradeoff between the errors during steady\n",
    "state, peak errors, and quick transition between models.\n",
    "\n",
    "\n",
    "### Section 3.3 Model Probabilities \n",
    "The model probability of the CV model was initialized to µ<sup>CV</sup><sub>0</sub> = 0.99 and the remaining model probabilities were all initialized to the value µ0 = (1− µ<sup>CV</sup><sub>0</sub>)/8 = 0.00125.\n",
    "A transition matrix $\\pi $ which is of size 9x9 is generated where the models are enumerated in the following order:\n",
    "CV, CT(14 deg /s), CT(−14 deg /s), CT(7 deg /s), CT(−7 deg /s), CTA(67 m/s2), CTA(−67 m/s2) , CTA(33 m/s2), CTA(−33 m/s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodal Estimation\n",
    "\n",
    "We have talked about individual process models but we haven't yet talked about how to maintain some beliefs about which behavior the driver intends to perform. This is the role of multimodal estimation algorithms. A simple approach to multimodal estimation is called autonomous multiple model estimation or AMM. While describing AMM, I will use the same notation that is used in a paper which I will link to later. The variable M represents the number of process models or behaviors and each variable mu represents the probability of behavior.\n",
    "\n",
    "<img src=\"./outputs/mm1.png\" width=\"300\" height=\"300\" />\n",
    "\n",
    "\n",
    "To understand how these probabilities are computed, let's go back to our T intersection example. Let's say we have two process models here. One to go straight and one to turn right and they both have Gaussian uncertainty. \n",
    "\n",
    "<img src=\"./outputs/mm2.png\" width=\"300\" height=\"300\" />\n",
    "\n",
    "Let's say that we observe this state for the vehicle at time k minus one and we observe this state for the vehicle at time k. \n",
    "\n",
    "<img src=\"./outputs/mm3.png\" width=\"300\" height=\"300\" />\n",
    "\n",
    "In order to compute the new probabilities for the behaviors based on the new observation, we will run our two process models for one step starting from the state at time k minus one.When we do this, we get these two expected states for time k.\n",
    "<img src=\"./outputs/mm4.png\" width=\"300\" height=\"300\" />\n",
    "\n",
    "\n",
    "If we just look at what the distribution on the vehicle's s coordinate looks like for the two expected states, this is what we see. Where the red curve gives the probability density function of S for turning right, the blue curve represents going straight and the observation at timestep k is somewhere here. We can see that this observation is substantially more consistent with turn right than it is with go straight. \n",
    "<img src=\"./outputs/mm5.png\" width=\"300\" height=\"300\" />\n",
    "\n",
    "This is measured by the likelihood of the observation as for each model and the probability of each behavior is a function of these likelihoods and of the probabilities computed in the previous timestep. The important quantity for the AMM is the ratio of these likelihoods after they get multiplied by the previous probability. The equation ends up looking like this,\n",
    "<img src=\"./outputs/mm6.png\" width=\"300\" height=\"300\" />\n",
    "\n",
    "where this term is the probability of model ($ \\mu_{k} $) I at timestep k. This term ($ \\mu_{k-1} $) is the probability of model I at timestep K minus one and this L term is the likelihood of the observation at time K for that model (bayesian probability equation). The denominator just serves to normalize our probabilities so that they all sum to one. M, in this situation would be two since we are only considering two maneuvers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Data Driven and Model Based Approaches\n",
    "\n",
    "So far you have learned about the two main approaches to prediction.\n",
    "\n",
    "1. Data-Driven Approaches\n",
    "Data-driven approaches solve the prediction problem in two phases:\n",
    "\n",
    "    Offline training\n",
    "    Online Prediction\n",
    "    \n",
    "1.1 Offline Training\n",
    "\n",
    "In this phase the goal is to feed some machine learning algorithm a lot of data to train it. For the trajectory clustering example this involved:\n",
    "\n",
    "    1. Define similarity - we first need a definition of similarity that agrees with human common-sense definition.\n",
    "    2. Unsupervised clustering - at this step some machine learning algorithm clusters the trajectories we've observed.\n",
    "    3. Define Prototype Trajectories - for each cluster identify some small number of typical \"prototype\" trajectories.\n",
    "\n",
    "1.2 Online Prediction\n",
    "Once the algorithm is trained we bring it onto the road. When we encounter a situation for which the trained algorithm is appropriate (returning to an intersection for example) we can use that algorithm to actually predict the trajectory of the vehicle. For the intersection example this meant:\n",
    "\n",
    "    1. Observe Partial Trajectory - As the target vehicle drives we can think of it leaving a \"partial trajectory\" behind it.\n",
    "    2. Compare to Prototype Trajectories - We can compare this partial trajectory to the corresponding parts of the prototype trajectories. When these partial trajectories are more similar (using the same notion of similarity defined earlier) their likelihoods should increase relative to the other trajectories.\n",
    "    3. Generate Predictions - For each cluster we identify the most likely prototype trajectory. We broadcast each of these trajectories along with the associated probability (see the image below).\n",
    "    \n",
    "<img src=\"./outputs/sum1.jpg\" width=\"500\" height=\"500\" />\n",
    "    \n",
    "2. Model Based Approaches\n",
    "\n",
    "You can think of model based solutions to the prediction problem as also having an \"offline\" and online component. In that view, this approach requires:\n",
    "\n",
    "    1. Defining process models (offline).\n",
    "    2. Using process models to compare driver behavior to what would be expected for each model.\n",
    "    3. Probabilistically classifying driver intent by comparing the likelihoods of various behaviors with a multiple-model algorithm.\n",
    "    4. Extrapolating process models to generate trajectories.\n",
    "\n",
    "2.1 Defining Process Models\n",
    "\n",
    "You saw how process models can vary in complexity from very simple...\n",
    "\n",
    "$ \\begin{bmatrix}\n",
    "s^{.} \\\\\n",
    "d^{.}\n",
    "\\end{bmatrix} \n",
    "$\n",
    "=\n",
    "$ \\begin{bmatrix}\n",
    "s0 \\\\\n",
    "0\n",
    "\\end{bmatrix} \n",
    "$ + **W**\n",
    "\n",
    "\n",
    "to very complex...\n",
    "\n",
    "$ \\begin{bmatrix}\n",
    "s^{..} \\\\\n",
    "d^{..}  \\\\\n",
    "\\theta ^{..}\n",
    "\\end{bmatrix} \n",
    "$\n",
    "=\n",
    "$ \\begin{bmatrix}\n",
    "\\theta ^{..} d^{.} + a_s \\\\\n",
    "- \\theta s^{.} + \\frac{2}{m}(F_{c,f} cos\\delta + F_{c,r})  \\\\\n",
    "\\frac{2}{I_z}(l_f F_{c,f} - l_r F_{c,r})\n",
    "\\end{bmatrix} \n",
    "$ + **W**\n",
    "\n",
    "\n",
    "2.2 Using Process Models\n",
    "\n",
    "Process Models are first used to compare a target vehicle's observed behavior to the behavior we would expect for each of the maneuvers we've created models for. The pictures below help explain how process models are used to calculate these likelihoods.\n",
    "\n",
    "<img src=\"./outputs/sum2.jpg\" width=\"500\" height=\"500\" />\n",
    "\n",
    "On the left we see two images of a car. At time k-1k−1 we predicted where the car would be if it were to go straight vs go right. Then at time kk we look at where the car actually is. The graph on the right shows the car's observed ss coordinate along with the probability distributions for where we expected the car to be at that time. In this case, the ss that we observe is substantially more consistent with turning right than going straight.\n",
    "\n",
    "2.3 Classifying Intent with Multiple Model Algorithm\n",
    "\n",
    "In the image at the top of the page you can see a bar chart representing probabilities of various clusters over time. Multiple model algorithms serve a similar purpose for model based approaches: they are responsible for maintaining beliefs for the probability of each maneuver. The algorithm we discussed is called the Autonomous Multiple Model algorithm (AMM). AMM can be summarized with this equation:\n",
    "\n",
    "$ \\mu_ {k}^{(i)} = \\frac {\\mu_ {k-1}^{(i)} L_{k}^{(i)}}{ \\sum_{j=1}^{M} \\mu^{j}_{k-1} L^{j}_{k}} $\n",
    "\n",
    "or, if we ignore the denominator (since it just serves to normalize the probabilities), we can capture the essence of this algorithm with\n",
    "\n",
    "$ \\mu_{k}^{(i)} \\hspace{5mm} \\alpha \\hspace{5mm}    \\mu_{k-1}^{(i)} L_{k}^{(i)} $\n",
    "\n",
    "where the $ \\mu_k^{(i)} $ is the probability that model number i is the correct model at time k and $ L_k^{(i)} $ is the likelihood for that model (as computed by comparison to process model).\n",
    "\n",
    "[Ref Paper](./a-comparative-study-of-multiple-model-algorithms-for-maneuvering-target-tracking.pdf)\n",
    "\n",
    "2.4 Trajectory Generation\n",
    "\n",
    "Trajectory generation is straightforward once we have a process model. We simply iterate our model over and over until we've generated a prediction that spans whatever time horizon we are supposed to cover. Note that each iteration of the process model will necessarily add uncertainty to our prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Hybrid Approaches\n",
    "\n",
    "So far you have seen that prediction can be done with model based or data driven approaches and you learned that model based approaches incorporate our knowledge of the objects motion dynamics with process models, handle uncertainty on maneuvers using multimodal estimators, and you have seen that there are many ways to implement model based approaches. In learning about data driven approaches you saw that there are many versions of data driven approaches and that these approaches can extract subtle patterns from training data which means they can produce predictions which are very well tailored to a specific driving situation.\n",
    "\n",
    "<img  src=\"./hybrid1.png\" width=\"300\" height=\"300\" />\n",
    "\n",
    "In practice, the best way to do prediction is often by taking a hybrid approach that takes advantage of the strengths of both types of approaches. Remember earlier when we talked about how model based approaches combine process models with a multimodal estimator? Well, the multimodal estimator could be replaced with a machine learning approach. \n",
    "<img  src=\"./hybrid2.png\" width=\"300\" height=\"300\" />\n",
    "To replace that component with a machine learning approach, the type of algorithm we need is a **classifier**. In the next few slides we will talk about how one such classifier known as **naive based classifier** works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Naive Bayes\n",
    "\n",
    "One strategy that is often used in hybrid approaches for behavior classification is to combine a classifier with a filter. We will show why. For now we will introduce a simple behavior classifier, Naive Bayes. Let's walk through how Naive Bayes works by using an example. We are going to reason on gender using statistics of two feature variables; height and weight. As an output we want the probability that a person is male or female given their height or weight. In a Naive Bayes classifier, the probability of being male given height and weight is just the probability of the height given male times the probability of that weight given male multiplied by the prior probability of being male something close to point five divided by the probability of the height and weight in the overall population. The reason why this algorithm is called Naive Bayes is that it assumes that all features contribute independently. And while in reality there is correlation between height and weight in people. In practice the independence assumption often winds up working. The equation about can be simplified. This term (denominator/total probability) will affect both probabilities male and female in the same way. It is just a normalization factor. This means we can first compute this part of the equation both for male and female and then compute the final probability of male given height and weight and probability of female given height male by normalizing them to make them sum to one. \n",
    "\n",
    "\n",
    "<img src=\"./nbayes1.png\" height=600 width=600 />\n",
    "\n",
    "<img src=\"./naive_bayes.gif\" height=600 width=600 />\n",
    "\n",
    "The problem is all about finding these terms. Often, we can assume it's a gaussian distribution for the feature variables. If you make this assumption the algorithm is then called Gaussian Naive Bayes. So in practice, implementing a good Gaussian Naive Bayes classifier is all about:\n",
    "\n",
    "\n",
    "1. selecting the correct feature variables for the classification problem. This is where we can use some human intution combined with feature selection algorithms to anticipate what factors are relevant for a given classification situation. Eye color for example would not be very useful in predicting gender. \n",
    "2. And identifying some good means and variances for different classes. And we can either guess these numbers or we can look at lots of data to learn them. For example, if you have access to lots of data about how drivers handle intersections and if you define some good features which indicate the intention's of drivers you could use Naive Bayes to compute the probability of each behavior at each time step. For the trajectory prediction part. You could use one of the following models we talked about earlier.\n",
    "\n",
    "<img src=\"./nbayes2.png\" height=600 width=600 />\n",
    "\n",
    "\n",
    "### Quiz:\n",
    "A car on a highway is approaching an exit ramp. We want to classify the driver's intent as \"go straight\" or \"exit right\". Which of the following state variables would be least useful to this classification?\n",
    "    1. s\n",
    "    2. rate of change of s (ds/dt)\n",
    "    3. d\n",
    "    4. rate of change of d (dd/dt)\n",
    "\n",
    "The s coordinate will not help in distinguishing between these two behaviors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Naive Bayes C++\n",
    "\n",
    "Implementing Naive Bayes\n",
    "In this exercise you will implement a Gaussian Naive Bayes classifier to predict the behavior of vehicles on a highway. In the image below you can see the behaviors you'll be looking for on a 3 lane highway (with lanes of 4 meter width). The dots represent the d (y axis) and s (x axis) coordinates of vehicles as they either...\n",
    "    \n",
    "    1. change lanes left (shown in blue)\n",
    "    2. keep lane (shown in black)\n",
    "    3. or change lanes right (shown in red)\n",
    "    \n",
    "<img src=\"./nbayes3.png\" height=400 width=400 />\n",
    "\n",
    "\n",
    "Your job is to write a classifier that can predict which of these three maneuvers a vehicle is engaged in given a single coordinate (sampled from the trajectories shown below).\n",
    "\n",
    "Each coordinate contains 4 features:\n",
    "\n",
    "* s\n",
    "* d\n",
    "* $\\dot{s} $\n",
    "* $\\dot{d} $\n",
    "\n",
    "\n",
    "You also know the lane width is 4 meters (this might be helpful in engineering additional features for your algorithm).\n",
    "\n",
    "### Instructions\n",
    "1. Implement the train(self, data, labels) method in the class GNB in classifier.cpp.\n",
    "\n",
    "    * Training a Gaussian Naive Bayes classifier consists of computing and storing the mean and standard deviation from the data for each label/feature pair. For example, given the label \"change lanes left” and the feature $\\dot{s} $ , it would be necessary to compute and store the mean and standard deviation of $\\dot{s} $ over all data points with the \"change lanes left” label.\n",
    "\n",
    "Additionally, it will be convenient in this step to compute and store the prior probability p(C_k) for each label C_k. This can be done by keeping track of the number of times each label appears in the training data.\n",
    "\n",
    "2. Implement the predict (self, observation) method in classifier.cpp.\n",
    "Given a new data point, prediction requires two steps:\n",
    "\n",
    "    1. Compute the conditional probabilities for each feature/label combination. For a feature x and label C with mean $ \\mu $ and standard deviation $ \\sigma $ (computed in training), the conditional probability can be computed using the formula [here](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Gaussian_naive_Bayes):\n",
    "    $p(x=v|C) = \\frac{1}{ \\sqrt{2 \\pi \\sigma^2}}  *  \\exp ^ {- \\frac{v-\\mu^2}{2 \\sigma^2}} $\n",
    "\n",
    "    Here v is the value of feature xx in the new data point.\n",
    "\n",
    "    2. Use the conditional probabilities in a Naive Bayes classifier. This can be done using the formula [here](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Constructing_a_classifier_from_the_probability_model):\n",
    "    \n",
    "    $ y=argmax_{k∈(1,…,K)}p(C_{k})\\prod_{i=1}^{n} p(x_i,v_i ∣ C_k) $\n",
    "    \n",
    "    In this formula, the argmax is taken over all possible labels $C_k $ and the product is taken over all features $x_i$ with values $v_i$\n",
    "\n",
    "When you want to test your classifier, run Test Run and check out the results.\n",
    "    \n",
    "**NOTE:** You are welcome to use some existing implementation of a Gaussian Naive Bayes classifier. But to get the best results you will still need to put some thought into what features you provide the algorithm when classifying. Though you will only be given the 4 coordinates listed above, you may find that by \"engineering\" features you may get better performance. For example: the raw value of the d coordinate may not be that useful. But d % lane_width might be helpful since it gives the relative position of a vehicle in it's lane regardless of which lane the vehicle is in. \n",
    "\n",
    "### Helpful Resources\n",
    "\n",
    "[sklearn documentation on GaussianNB](http://scikit-learn.org/stable/modules/naive_bayes.html#gaussian-naive-bayes)\n",
    "\n",
    "[Wikipedia article on Naive Bayes / GNB](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Gaussian_naive_Bayes)\n",
    "\n",
    "### Extra Practice\n",
    "\n",
    "Provided in one of the links below is python_extra_practice, which is the same problem but written in Python that you can optionally go through for extra coding practice. The Python solution is available at the python_solution link. If you get stuck on the quiz see if you can convert the python solution to C++ and pass the classroom quiz with it. The last link Nd013_Pred_Data has all the training and testing data for this problem in case you want to run the problem offline.\n",
    "\n",
    "\n",
    "### Supporting Materials\n",
    "[Nd013 Pred Data](nd013-pred-data.zip)\n",
    "\n",
    "[python_extra_practice](predictionexercise.zip)\n",
    "\n",
    "[python_solution](predicition-solution.zip)\n",
    "\n",
    "\n",
    "\n",
    "Students have reported Load_State function in main.cpp is not loading data properly from train_states.txt and test_states.txt since is istringstream is not implemented for comma (',') separated data. Several students have found working solutions [here](https://github.com/udacity/sdc-issue-reports/issues/914), that may help in determining your own solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution for C code\n",
    "\n",
    "1. [classifier.h](./src/classifier.h)     : has header for GNB class\n",
    "2. [classifier.cpp](./src/classifier.cpp) : train and predict methods\n",
    "3. [main.cpp](./src/main.cpp)             : main file that loads data, trains (calculate mean and stddev for s/d/$\\dot{s},\\dot{d}$    \n",
    "\n",
    "To Run the exercise:\n",
    "mkdir build\n",
    "cd build\n",
    "cmake ..\n",
    "make\n",
    "./Prediction\n",
    "\n",
    "84.4 % accuracy achieved\n",
    "\n",
    "###Python script is not tried yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digression\n",
    "#### Mathematical Equations in MArkup\n",
    "\n",
    "Latex: \n",
    "$$e^x=\\sum_{i=0}^\\infty \\frac{1}{i!}x^i$$\n",
    "\n",
    "### <over>,\\&,; doesn't work\n",
    "Currently, the best way of including equations in HTML documents is to first write the document in LaTeX and then use the latex2html filter to create the corresponding HTML document, together with the equations as a number of bitmap files*1. The previous draft of the HTML+ specification described a way of embedding LaTeX equations in HTML+ documents. Unfortunately, it now seems too cumbersome to form a practical solution, and has been dropped.\n",
    "The following is a preliminary proposal for representing equations directly as HTML+ using an SGML-based notation, inspired by the approach taken by LaTeX. It is intended to cover the majority of users needs, rather than aiming for complete coverage. This makes it practical to use a simplified notation compared with richer notations, e.g. the ISO 12083 Maths DTD. An experimental browser supporting the MATH element is being developed at CERN.\n",
    "\n",
    "<math>\n",
    "\tH(s) = ∫<sub>0</sub><sup>∞</sup> e<sup>-st</sup> h(t) dt\n",
    "</math>\n",
    "\n",
    "The mathematical symbols are given with their standard ISO entity names. SUB and SUP are used to specify subscripts and superscripts. For integral signs and related operators, the subscript/superscript text is centered over the symbol, otherwise it appears to the right as shown in the preceding example. The BOX and OVER elements allow you to define more complex equations, as in:\n",
    "\n",
    "<math>\n",
    "\tC <box>dV<sub>out</sub><over>dt</box> = I<sub>b</sub>\n",
    "\t&tanh;(<box>κ(V<sub>in</sub>-V<sub>out</sub>)<over>2</box>)\n",
    "</math>\n",
    "\n",
    "The BOX element can be used to generally group items and can be thought of as non-printing parentheses. The OVER element is optional and divides the box into numerator and denominator. The ARRAY element is used to specify arrays for expressions like:\n",
    "\n",
    "\n",
    "The ARRAY element has a single attribute ALIGN which specifies the number of columns and the alignment of items within the columns. For each column there is a single letter that specifies how items in that column should be positioned: c for centered, l for flush left or r for flush right. Each item in the array must follow an <ITEM> element.\n",
    "\n",
    "The preceding example is represented by:\n",
    "\n",
    "<math>\n",
    "\t(<array align=\"c\"> <item>\n",
    "\t\t&ldet;<array align=\"cc\">\n",
    "\t\t\t<item>x<sub>11</sub>\n",
    "\t\t\t<item>x<sub>12</sub>\n",
    "\t\t\t<item>x<sub>21</sub>\t\t\t\n",
    "\t\t\t<item>x<sub>22</sub>\n",
    "\t\t</array><rd>&rdet;\n",
    "\t\t<item> y <item> z\n",
    "\t</array>)\n",
    "</math>\n",
    "\n",
    "The browser is responsible for working out the vertical and horizontal spacing required for the array. Parentheses*2 are stretched to match the size of the array. Arrays can be used only in the context of the MATH element. The TABLE element should be used for other contexts.\n",
    "\n",
    "Spaces are significant within the MATH element, and used for disambiguation, as can be seen in the following two examples:\n",
    "\n",
    "<math>\n",
    "    &int;<sub>i</sub><sup>j</sup> x\n",
    "    \n",
    "</math>\n",
    "\n",
    "<math>\n",
    "    &int; <sub>i</sub><sup>j</sup>x\n",
    "    \n",
    "</math>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
